#!/usr/bin/env python3
"""
PyTorchç‰ˆæœ¬çš„LSTMè´Ÿè·é¢„æµ‹æ¨¡å‹è®­ç»ƒè„šæœ¬
"""

import os
import numpy as np
import matplotlib.pyplot as plt
from data_preprocessor import DataPreprocessor
from lstm_model_pytorch import LSTMLoadPredictor
import json
import torch

def main():
    print("ğŸ”¥ PyTorch LSTMè´Ÿè·é¢„æµ‹æ¨¡å‹è®­ç»ƒ")
    print("=" * 50)
    
    # è®¾ç½®éšæœºç§å­
    torch.manual_seed(42)
    np.random.seed(42)
    
    # æ£€æŸ¥æ•°æ®æ–‡ä»¶
    data_file = 'data/load_data.csv'
    if not os.path.exists(data_file):
        print(f"æ•°æ®æ–‡ä»¶ {data_file} ä¸å­˜åœ¨!")
        print("è¯·å…ˆè¿è¡Œ: python data_generator.py")
        return
    
    # 1. æ•°æ®é¢„å¤„ç†
    print("\n1. ğŸ“Š æ•°æ®é¢„å¤„ç†...")
    preprocessor = DataPreprocessor(sequence_length=24, prediction_steps=1)
    
    df = preprocessor.load_data(data_file)
    print(f"âœ… åŠ è½½æ•°æ®: {df.shape}")
    print(f"ğŸ“… æ—¶é—´èŒƒå›´: {df['datetime'].min()} åˆ° {df['datetime'].max()}")
    
    data = preprocessor.prepare_data(df, test_size=0.2, val_size=0.1)
    X_train, y_train = data['X_train'], data['y_train']
    X_val, y_val = data['X_val'], data['y_val']
    X_test, y_test = data['X_test'], data['y_test']
    
    print(f"âœ… è®­ç»ƒé›†: X={X_train.shape}, y={y_train.shape}")
    print(f"âœ… éªŒè¯é›†: X={X_val.shape}, y={y_val.shape}")
    print(f"âœ… æµ‹è¯•é›†: X={X_test.shape}, y={y_test.shape}")
    
    preprocessor.save_scalers('models/scalers_pytorch.pkl')
    
    # 2. æ„å»ºæ¨¡å‹
    print("\n2. ğŸ¤– æ„å»ºPyTorch LSTMæ¨¡å‹...")
    predictor = LSTMLoadPredictor(
        sequence_length=24,
        n_features=X_train.shape[2],
        prediction_steps=1
    )
    
    # æ„å»ºæ¨¡å‹
    predictor.build_model(
        hidden_sizes=[64, 32],
        dropout_rate=0.2,
        learning_rate=0.001
    )
    
    # 3. è®­ç»ƒæ¨¡å‹
    print("\n3. ğŸš€ å¼€å§‹è®­ç»ƒ...")
    history = predictor.train(
        X_train, y_train,
        X_val, y_val,
        epochs=50,      # å‡å°‘è½®æ•°ä¾¿äºæ¼”ç¤º
        batch_size=32,
        patience=10,
        save_path='models/lstm_model_pytorch.pth'
    )
    
    # 4. è¯„ä¼°æ¨¡å‹
    print("\n4. ğŸ“ˆ æ¨¡å‹è¯„ä¼°...")
    metrics, predictions, y_true = predictor.evaluate(X_test, y_test, preprocessor)
    
    # 5. å¯è§†åŒ–ç»“æœ
    print("\n5. ğŸ“Š ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...")
    
    # ç»˜åˆ¶è®­ç»ƒå†å²
    predictor.plot_training_history()
    
    # ç»˜åˆ¶é¢„æµ‹ç»“æœ
    plt.figure(figsize=(15, 10))
    n_samples = min(168, len(predictions))  # æ˜¾ç¤ºä¸€å‘¨æ•°æ®
    
    # å­å›¾1: é¢„æµ‹å¯¹æ¯”
    plt.subplot(3, 1, 1)
    plt.plot(y_true[:n_samples], label='å®é™…è´Ÿè·', linewidth=2, alpha=0.8)
    plt.plot(predictions[:n_samples], label='é¢„æµ‹è´Ÿè·', linewidth=2, alpha=0.8)
    plt.title('PyTorch LSTM è´Ÿè·é¢„æµ‹ç»“æœå¯¹æ¯”', fontsize=14, fontweight='bold')
    plt.xlabel('æ—¶é—´ (å°æ—¶)')
    plt.ylabel('è´Ÿè· (MW)')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    # å­å›¾2: è¯¯å·®åˆ†æ
    plt.subplot(3, 1, 2)
    errors = predictions[:n_samples] - y_true[:n_samples]
    plt.plot(errors, color='red', alpha=0.7, linewidth=2)
    plt.axhline(y=0, color='black', linestyle='--', alpha=0.5)
    plt.title('é¢„æµ‹è¯¯å·®åˆ†æ', fontsize=14, fontweight='bold')
    plt.xlabel('æ—¶é—´ (å°æ—¶)')
    plt.ylabel('è¯¯å·® (MW)')
    plt.grid(True, alpha=0.3)
    
    # å­å›¾3: æ•£ç‚¹å›¾
    plt.subplot(3, 1, 3)
    plt.scatter(y_true[:n_samples], predictions[:n_samples], alpha=0.6, s=20)
    
    # æ·»åŠ ç†æƒ³é¢„æµ‹çº¿
    min_val = min(y_true[:n_samples].min(), predictions[:n_samples].min())
    max_val = max(y_true[:n_samples].max(), predictions[:n_samples].max())
    plt.plot([min_val, max_val], [min_val, max_val], 'r--', alpha=0.8, linewidth=2)
    
    plt.title('å®é™…å€¼ vs é¢„æµ‹å€¼', fontsize=14, fontweight='bold')
    plt.xlabel('å®é™…è´Ÿè· (MW)')
    plt.ylabel('é¢„æµ‹è´Ÿè· (MW)')
    plt.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig('models/pytorch_prediction_results.png', dpi=300, bbox_inches='tight')
    plt.show()
    
    # 6. ä¿å­˜ç»“æœ
    print("\n6. ğŸ’¾ ä¿å­˜ç»“æœ...")
    with open('models/pytorch_evaluation_metrics.json', 'w') as f:
        json.dump(metrics, f, indent=2)
    
    # ä¿å­˜è®­ç»ƒå†å²
    with open('models/pytorch_training_history.json', 'w') as f:
        json.dump(history, f, indent=2)
    
    print("\n" + "="*60)
    print("ğŸ‰ PyTorch LSTM è®­ç»ƒå®Œæˆ!")
    print("="*60)
    print(f"ğŸ“ æ¨¡å‹æ–‡ä»¶: models/lstm_model_pytorch.pth")
    print(f"ğŸ“ é¢„å¤„ç†å™¨: models/scalers_pytorch.pkl")
    print(f"ğŸ“ è¯„ä¼°æŒ‡æ ‡: models/pytorch_evaluation_metrics.json")
    print(f"ğŸ“Š è®­ç»ƒå†å²: models/pytorch_training_history.json")
    print(f"ğŸ“ˆ å¯è§†åŒ–å›¾è¡¨: models/pytorch_prediction_results.png")
    
    print(f"\nğŸ“Š æœ€ç»ˆæ€§èƒ½æŒ‡æ ‡:")
    print(f"ğŸ¯ RMSE: {metrics['RMSE']:.2f} MW")
    print(f"ğŸ¯ MAE:  {metrics['MAE']:.2f} MW")
    print(f"ğŸ¯ MAPE: {metrics['MAPE']:.2f}%")
    print(f"ğŸ¯ RÂ²:   {metrics['RÂ²']:.4f}")
    
    # æ£€æŸ¥GPUä½¿ç”¨æƒ…å†µ
    if torch.cuda.is_available():
        print(f"\nğŸš€ ä½¿ç”¨äº†GPUåŠ é€Ÿ: {torch.cuda.get_device_name()}")
    else:
        print(f"\nğŸ’» ä½¿ç”¨CPUè®­ç»ƒ")
        
    print("\nâœ… å¯ä»¥å¼€å§‹ä½¿ç”¨æ¨¡å‹è¿›è¡Œé¢„æµ‹äº†!")

if __name__ == "__main__":
    main()